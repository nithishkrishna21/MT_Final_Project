{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174cd4bb-24a4-4f14-9cf3-b3d622cce089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
    "from google.transliteration import transliterate_text\n",
    "from indictrans import Transliterator\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7d5d33-c5f2-45cb-82dd-bd5319c53825",
   "metadata": {},
   "outputs": [],
   "source": [
    "roman_scripts_file_path = \"../datasets/dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.test.roman.txt\"\n",
    "native_scripts_file_path = \"../datasets//dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.test.native.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d84103-4192-4dd7-849e-5c741c0f8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "native_lines = []\n",
    "with open(native_scripts_file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        native_lines.append(line)\n",
    "        # cleaned_line = line.replace('-', '')\n",
    "        #cleaned_line = re.sub(r'[\"\\'#,]', '', line)\n",
    "        #native_lines.append(cleaned_line)\n",
    "\n",
    "romanized_lines = []\n",
    "with open(roman_scripts_file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        romanized_lines.append(line)\n",
    "        # cleaned_line = line.replace('-', '')\n",
    "        #cleaned_line = re.sub(r'[\"\\',]', '', line)\n",
    "        #romanized_lines.append(cleaned_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b608ad7b-881c-4f39-aa02-3c198d3af874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(native_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca60a82-60ed-44f5-89af-ef69e18763fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(romanized_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb827b24-c063-454b-b664-d8909aaa08ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Hinglish  \\\n",
      "0  Kumbh rashi men janme log carbanion se bhari e...   \n",
      "1                         Iska ulat bhi satya hai.\\n   \n",
      "2  kuch devta jo mukhyatah nagar devta the, apne ...   \n",
      "3  Tel ke utpadan men sansar men Romania ka chhat...   \n",
      "4  Banarasi Lal se milkar police ne sara bhed pra...   \n",
      "\n",
      "                                               Hindi  \n",
      "0  कुंभ राशि में जन्मे लोग संभावनाओं से भरी एक जग...  \n",
      "1                             इसका उलट भी सत्य है।\\n  \n",
      "2  कुछ देवता जो मुख्यत: नगर देवता थे, अपने संप्रद...  \n",
      "3  तेल के उत्पादन में संसार में रोमानिया का छठा स...  \n",
      "4  बनारसी लाल से मिलकर पुलिस ने सारा भेद प्राप्त ...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Hinglish': romanized_lines, 'Hindi': native_lines})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bfe755-3fe6-430e-9870-2e4e66895320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "490055cf-5e02-4665-bd08-16d4b0a58811",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = df.sample(n = 100, replace = False, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b07ff5-9306-47d1-b48b-0299d21de0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501             yahan par bhagwan Bahubali ki 18 meter\\n\n",
      "2586                                      samjha-parkha\\n\n",
      "2653    jab kamishnar Arun ke saath baat kar rahe the,...\n",
      "1055    Joshi ne ASI men purattwavidon ke samarthan ka...\n",
      "705     Ageti Parikshit Sharma Sanskrut Bhasha ke prat...\n",
      "                              ...                        \n",
      "4740               karnatak: devarkadu, nagban, nagkudu\\n\n",
      "2940    adhikansh kavita barabar avadhi aur vrajbhasha...\n",
      "3456             iaka swar do sinhon dwara rakshit hai.\\n\n",
      "373     ek saal bad, raja sahib ne istifa de diya aur ...\n",
      "79      prabandhan, raktadhan men kabhi kabhi sahayak ...\n",
      "Name: Hinglish, Length: 100, dtype: object\n",
      "<class 'numpy.ndarray'>\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "hinglish_sentences = sampled_df['Hinglish']\n",
    "print(hinglish_sentences)\n",
    "\n",
    "hinglish_sentences = hinglish_sentences.values\n",
    "print(type(hinglish_sentences))\n",
    "print(hinglish_sentences.shape)\n",
    "\n",
    "hindi_true = list(sampled_df['Hindi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6979405-cdce-4ab0-8c7f-73c9d04c0f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transliterating sentence  1\n",
      "Original Code mized text : yahan par bhagwan Bahubali ki 18 meter\n",
      "\n",
      "Original Native Hindi convertion : यहाँ पर भगवान बाहुबली की १८ मी.\n",
      "\n",
      "Transliterated to Hindi : यहाँ पर भगवान बाहुबली की 18 मीटर\n",
      "\n",
      "Average BLEU score : 0.6147881529512643 \n",
      "\n",
      "Transliterating sentence  11\n",
      "Original Code mized text : Stivan S Reinmund: purv chairman aur CEO, Pepsiko In\n",
      "\n",
      "Original Native Hindi convertion : स्टीवन एस रेइनमुंड: पूर्व चेयरमैन और सीईओ, पेप्सीको इंक\n",
      "\n",
      "Transliterated to Hindi : स्टिवन स रेनमंड: पूर्व चेयरमाण और सियो, पेप्सिको इन\n",
      "\n",
      "Average BLEU score : 0.3678757699675088 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithish\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Nithish\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Nithish\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transliterating sentence  21\n",
      "Original Code mized text : vaha ke bhudrishya ka dekhkar use pata chala ki 'manav shram ke samuchit prayog se' us khsetra ki to kaya hi palat gai hai.\n",
      "\n",
      "Original Native Hindi convertion : वहां के भूदॄश्य का देखकर उसे पता चला कि ‘मानव श्रम के समुचित प्रयोग से’ उस क्षेत्र की तो काया ही पलट गई है।\n",
      "\n",
      "Transliterated to Hindi : वाहा के भूद्रीश्य का देखकर उसे पता चला की 'मानव श्रम के समुचित प्रयोग से' उस ख्सेत्र की तो काया ही पलट गई हैं.\n",
      "\n",
      "Average BLEU score : 0.3800078134465459 \n",
      "\n",
      "Transliterating sentence  31\n",
      "Original Code mized text : iska vishisht vidyutiya pratirodh 4.9 hai jo platinum ka lagbhag adha hai.\n",
      "\n",
      "Original Native Hindi convertion : इसका विशिष्ट विद्युतीय प्रतिरोध ४.९ है जो प्लैटिनम का लगभग आधा है।\n",
      "\n",
      "Transliterated to Hindi : इसका विशिष्ट विद्युतिया प्रतिरोध 4.9 हैं जो प्लेटिनम का लगभग आधा हैं.\n",
      "\n",
      "Average BLEU score : 0.38058544213481127 \n",
      "\n",
      "Transliterating sentence  41\n",
      "Original Code mized text : ek baar to unhone Jawaharlal Nehru ko patr likhkar krantikari navyuakon ka saath dene par buri tarah fatkaar bhi lagaai thee.\n",
      "\n",
      "Original Native Hindi convertion : एक बार तो उन्होंने जवाहरलाल नेहरू को पत्र लिखकर क्रान्तिकारी नवयुवकों का साथ देने पर बुरी तरह फटकार भी लगायी थी।\n",
      "\n",
      "Transliterated to Hindi : एक बार तो उन्होंने जवाहरलाल नेहरू को पत्र लिखकर क्रांतिकारी नव्युकों का साथ देने पर बुरी तरह फत्कार भी लगाई थी.\n",
      "\n",
      "Average BLEU score : 0.35516310620078145 \n",
      "\n",
      "Transliterating sentence  51\n",
      "Original Code mized text : ek vidhi inke Iksponenshiyal falan ke falan ke roop men paribhashit karti hai-\n",
      "\n",
      "Original Native Hindi convertion : एक विधि इनको इक्सपोनेन्शियल फलन के फलन के रूप में परिभाषित करती है-\n",
      "\n",
      "Transliterated to Hindi : एक विधि इनकी इकस्पोनेन्शियल फलन के फलन के रूप में परिभाषित करती हैं-\n",
      "\n",
      "Average BLEU score : 0.35583913699568037 \n",
      "\n",
      "Transliterating sentence  61\n",
      "Original Code mized text : Sanvidhan ke Lesotho men aya bal ke prakashan ke baad prarambh adesh hai .\n",
      "\n",
      "Original Native Hindi convertion : संविधान के लेसोथो में आया बल के प्रकाशन के बाद प्रारंभ आदेश है ।\n",
      "\n",
      "Transliterated to Hindi : संविधान के लेसोथो में आया बाल के प्रकाषन के बाद प्रारंभ आदेश हैं .\n",
      "\n",
      "Average BLEU score : 0.35301399243830606 \n",
      "\n",
      "Transliterating sentence  71\n",
      "Original Code mized text : kai suvidhayen aur adhikansh credit card bhi grahakon ko anumati dete hain ki ve baink ki jaankaari pradan karke bhugtaan kar sakte hain aur aadata ko grahak ke khaate se (pratyaksh naame) bhugtaan ka aahran karne dete hain.\n",
      "\n",
      "Original Native Hindi convertion : कई सुविधाएं और अधिकांश क्रेडिट कार्ड भी ग्राहकों को अनुमति देते हैं कि वे बैंक की जानकारी प्रदान करके भुगतान कर सकते हैं और आदाता को ग्राहक के खाते से (प्रत्यक्ष नामे) भुगतान का आहरण करने देते हैं।\n",
      "\n",
      "Transliterated to Hindi : कई सुविधाएं और अधिकांश क्रेडिट कार्ड भी ग्रहकों को अनुमति देते हैं की वे बैंक की जानकारी प्रदन करके भुगतान कर सकते हैं और आदाता को ग्रहक के खाते से (प्रत्यक्ष नामे) भुगतान का आहरण करने देते हैं.\n",
      "\n",
      "Average BLEU score : 0.35540094617279955 \n",
      "\n",
      "Transliterating sentence  81\n",
      "Original Code mized text : ramayana aur mahabharata ki gathaon dwara yeh adarsh jan jan tak pahunchte hain.\n",
      "\n",
      "Original Native Hindi convertion : रामायण और महाभारत की गाथाओं द्वारा यह आदर्श जन जन तक पहुँचते हैं।\n",
      "\n",
      "Transliterated to Hindi : रामायण और महाभारत की गठओं द्वारा यह आदर्श जान जान तक पहुँचते हैं.\n",
      "\n",
      "Average BLEU score : 0.3177535049143352 \n",
      "\n",
      "Transliterating sentence  91\n",
      "Original Code mized text : ismen Safed, sugandhit Pushp lagte hain.\n",
      "\n",
      "Original Native Hindi convertion : इसमें सफेद, सुगंधित पुष्प लगते हैं।\n",
      "\n",
      "Transliterated to Hindi : इसमें सफ़ेद, सुगांधित पुष्प लगते हैं.\n",
      "\n",
      "Average BLEU score : 0.3260723951580097 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing using LIBINC transliterator\n",
    "# trn = Transliterator(source='eng', target='hin', build_lookup=True, decode='beamsearch')\n",
    "trn = Transliterator(source='eng', target='hin', build_lookup=True)\n",
    "bleu_scores = []\n",
    "for i in range(hinglish_sentences.size):\n",
    "\n",
    "    transformed_sentence = trn.transform(hinglish_sentences[i])\n",
    "    reference = [hindi_true[i].split()]\n",
    "    # print(transformed_sentence)\n",
    "    transformed_tokens = transformed_sentence.split()\n",
    "    bleu_score = sentence_bleu(reference, transformed_tokens)\n",
    "    bleu_scores.append(bleu_score)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(\"Transliterating sentence \", i+1)\n",
    "        print('Original Code mized text :', hinglish_sentences[i])\n",
    "        print('Original Native Hindi convertion :', hindi_true[i])\n",
    "        print('Transliterated to Hindi :', transformed_sentence)\n",
    "        print('Average BLEU score :', np.mean(bleu_scores), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4133b6a7-353f-4e2e-a525-6e069ce441fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Bleu Score for Train Set :  0.3185566633653254\n"
     ]
    }
   ],
   "source": [
    "average_bleu_score = np.mean(bleu_scores)\n",
    "print('Average Bleu Score for Train Set : ', average_bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb8132a-faa2-41f3-a7e6-41ba059495da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transliterating sentence  1\n",
      "Original Code mized text : yahan par bhagwan Bahubali ki 18 meter\n",
      "\n",
      "Original Native Hindi convertion : यहाँ पर भगवान बाहुबली की १८ मी.\n",
      "\n",
      "Transliterated to Hindi : यहन् पर् भग्वन् Bअहुबलि कि १८ मेतेर्\n",
      "\n",
      "Average BLEU score : 1.1200407237786664e-231 \n",
      "\n",
      "Transliterating sentence  11\n",
      "Original Code mized text : Stivan S Reinmund: purv chairman aur CEO, Pepsiko In\n",
      "\n",
      "Original Native Hindi convertion : स्टीवन एस रेइनमुंड: पूर्व चेयरमैन और सीईओ, पेप्सीको इंक\n",
      "\n",
      "Transliterated to Hindi : Sतिवन् S ऱेइन्मुन्द्: पुर्व् चैर्मन् और् CEO, Pएप्सिको ईन्\n",
      "\n",
      "Average BLEU score : 2.349485101993388e-79 \n",
      "\n",
      "Transliterating sentence  21\n",
      "Original Code mized text : vaha ke bhudrishya ka dekhkar use pata chala ki 'manav shram ke samuchit prayog se' us khsetra ki to kaya hi palat gai hai.\n",
      "\n",
      "Original Native Hindi convertion : वहां के भूदॄश्य का देखकर उसे पता चला कि ‘मानव श्रम के समुचित प्रयोग से’ उस क्षेत्र की तो काया ही पलट गई है।\n",
      "\n",
      "Transliterated to Hindi : वह के भुद्रिश्य क देख्कर् उसे पत चल कि 'मनव् श्रम् के समुचित् प्रयोग् से' उस् ख्सेत्र कि तो कय हि पलत् गै है।\n",
      "\n",
      "Average BLEU score : 1.230682672472727e-79 \n",
      "\n",
      "Transliterating sentence  31\n",
      "Original Code mized text : iska vishisht vidyutiya pratirodh 4.9 hai jo platinum ka lagbhag adha hai.\n",
      "\n",
      "Original Native Hindi convertion : इसका विशिष्ट विद्युतीय प्रतिरोध ४.९ है जो प्लैटिनम का लगभग आधा है।\n",
      "\n",
      "Transliterated to Hindi : इस्क विशिश्त् विद्युतिय प्रतिरोध् ४।९ है जो प्लतिनुम् क लग्भग् अध है।\n",
      "\n",
      "Average BLEU score : 8.336882619976538e-80 \n",
      "\n",
      "Transliterating sentence  41\n",
      "Original Code mized text : ek baar to unhone Jawaharlal Nehru ko patr likhkar krantikari navyuakon ka saath dene par buri tarah fatkaar bhi lagaai thee.\n",
      "\n",
      "Original Native Hindi convertion : एक बार तो उन्होंने जवाहरलाल नेहरू को पत्र लिखकर क्रान्तिकारी नवयुवकों का साथ देने पर बुरी तरह फटकार भी लगायी थी।\n",
      "\n",
      "Transliterated to Hindi : एक् बार् तो उन्होने Jअवहर्लल् णेह्रु को पत्र् लिख्कर् क्रन्तिकरि नव्युअकोन् क साथ् देने पर् बुरि तरह् fअत्कार् भि लगाइ थेए।\n",
      "\n",
      "Average BLEU score : 6.3034966151042114e-80 \n",
      "\n",
      "Transliterating sentence  51\n",
      "Original Code mized text : ek vidhi inke Iksponenshiyal falan ke falan ke roop men paribhashit karti hai-\n",
      "\n",
      "Original Native Hindi convertion : एक विधि इनको इक्सपोनेन्शियल फलन के फलन के रूप में परिभाषित करती है-\n",
      "\n",
      "Transliterated to Hindi : एक् विधि इन्के ईक्स्पोनेन्शियल् fअलन् के fअलन् के रोओप् मेन् परिभशित् कर्ति है-\n",
      "\n",
      "Average BLEU score : 5.067516886652406e-80 \n",
      "\n",
      "Transliterating sentence  61\n",
      "Original Code mized text : Sanvidhan ke Lesotho men aya bal ke prakashan ke baad prarambh adesh hai .\n",
      "\n",
      "Original Native Hindi convertion : संविधान के लेसोथो में आया बल के प्रकाशन के बाद प्रारंभ आदेश है ।\n",
      "\n",
      "Transliterated to Hindi : Sअन्विधन् के ळेसोथो मेन् अय बल् के प्रकशन् के बाद् प्ररम्भ् अदेश् है ।\n",
      "\n",
      "Average BLEU score : 4.2367764134306994e-80 \n",
      "\n",
      "Transliterating sentence  71\n",
      "Original Code mized text : kai suvidhayen aur adhikansh credit card bhi grahakon ko anumati dete hain ki ve baink ki jaankaari pradan karke bhugtaan kar sakte hain aur aadata ko grahak ke khaate se (pratyaksh naame) bhugtaan ka aahran karne dete hain.\n",
      "\n",
      "Original Native Hindi convertion : कई सुविधाएं और अधिकांश क्रेडिट कार्ड भी ग्राहकों को अनुमति देते हैं कि वे बैंक की जानकारी प्रदान करके भुगतान कर सकते हैं और आदाता को ग्राहक के खाते से (प्रत्यक्ष नामे) भुगतान का आहरण करने देते हैं।\n",
      "\n",
      "Transliterated to Hindi : कै सुविधयेन् और् अधिकन्श् cरेदित् cअर्द् भि ग्रहकोन् को अनुमति देते हैन् कि वे बैन्क् कि जान्कारि प्रदन् कर्के भुग्तान् कर् सक्ते हैन् और् आदत को ग्रहक् के खाते से (प्रत्यक्श् नामे) भुग्तान् क आह्रन् कर्ने देते हैन्।\n",
      "\n",
      "Average BLEU score : 0.002046292891880485 \n",
      "\n",
      "Transliterating sentence  81\n",
      "Original Code mized text : ramayana aur mahabharata ki gathaon dwara yeh adarsh jan jan tak pahunchte hain.\n",
      "\n",
      "Original Native Hindi convertion : रामायण और महाभारत की गाथाओं द्वारा यह आदर्श जन जन तक पहुँचते हैं।\n",
      "\n",
      "Transliterated to Hindi : रमयन और् महभरत कि गथओन् द्वर येह् अदर्श् जन् जन् तक् पहुन्च्ते हैन्।\n",
      "\n",
      "Average BLEU score : 0.0017936641397964745 \n",
      "\n",
      "Transliterating sentence  91\n",
      "Original Code mized text : ismen Safed, sugandhit Pushp lagte hain.\n",
      "\n",
      "Original Native Hindi convertion : इसमें सफेद, सुगंधित पुष्प लगते हैं।\n",
      "\n",
      "Transliterated to Hindi : इस्मेन् Sअfएद्, सुगन्धित् Pउश्प् लग्ते हैन्।\n",
      "\n",
      "Average BLEU score : 0.0015965581903682905 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithish\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Nithish\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Nithish\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# The path to the local git repo for Indic NLP library\n",
    "INDIC_NLP_LIB_HOME=r\"C:\\Johns Hopkins\\sem1\\Machine Translation\\MT Final Project\\IndicTrans2\\indic_nlp_library\"\n",
    "\n",
    "# The path to the local git repo for Indic NLP Resources\n",
    "INDIC_NLP_RESOURCES=r\"C:\\Johns Hopkins\\sem1\\Machine Translation\\MT Final Project\\IndicTrans2\\indic_nlp_resources\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\n",
    "\n",
    "from indicnlp import common\n",
    "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
    "\n",
    "from indicnlp import loader\n",
    "loader.load()\n",
    "\n",
    "# Testing using AI4Bharath transliterator\n",
    "ai4b_bleu_scores = []\n",
    "lang = 'hi'\n",
    "for i in range(hinglish_sentences.size):\n",
    "\n",
    "    transformed_sentence = ItransTransliterator.from_itrans(hinglish_sentences[i],lang)\n",
    "    reference = [hindi_true[i].split()]\n",
    "    # print(transformed_sentence)\n",
    "    transformed_tokens = transformed_sentence.split()\n",
    "    bleu_score = sentence_bleu(reference, transformed_tokens)\n",
    "    ai4b_bleu_scores.append(bleu_score)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(\"Transliterating sentence \", i+1)\n",
    "        print('Original Code mized text :', hinglish_sentences[i])\n",
    "        print('Original Native Hindi convertion :', hindi_true[i])\n",
    "        print('Transliterated to Hindi :', transformed_sentence)\n",
    "        print('Average BLEU score :', np.mean(ai4b_bleu_scores), '\\n')\n",
    "\n",
    "average_bleu_score = np.mean(ai4b_bleu_scores)\n",
    "print('Average Bleu Score for Train Set : ', average_bleu_score)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f47b712-8411-49b6-9866-741eacbdded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Bleu Score for Train Set :  0.0014528679532351443\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab375181-8e6e-42f4-b3c9-5e32be4ac11c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Transliterating sentence  1\n",
      "Original Code mized text : yahan par bhagwan Bahubali ki 18 meter\n",
      "\n",
      "Original Native Hindi convertion : यहाँ पर भगवान बाहुबली की १८ मी.\n",
      "\n",
      "Transliterated to Hindi : यहाँ पर भगवन बाहुबली की १८ मीटर\n",
      "Average BLEU score : 6.313993041533344e-78 \n",
      "\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "Transliterating sentence  11\n",
      "Original Code mized text : Stivan S Reinmund: purv chairman aur CEO, Pepsiko In\n",
      "\n",
      "Original Native Hindi convertion : स्टीवन एस रेइनमुंड: पूर्व चेयरमैन और सीईओ, पेप्सीको इंक\n",
      "\n",
      "Transliterated to Hindi : स्टीवन स रेमण्ड: पूर्व चेयरमैन और सीईओ, पेप्सिको इन\n",
      "Average BLEU score : 0.41052323410637204 \n",
      "\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Transliterating sentence  21\n",
      "Original Code mized text : vaha ke bhudrishya ka dekhkar use pata chala ki 'manav shram ke samuchit prayog se' us khsetra ki to kaya hi palat gai hai.\n",
      "\n",
      "Original Native Hindi convertion : वहां के भूदॄश्य का देखकर उसे पता चला कि ‘मानव श्रम के समुचित प्रयोग से’ उस क्षेत्र की तो काया ही पलट गई है।\n",
      "\n",
      "Transliterated to Hindi : वह के भूदृश्य का देखकर उसे पता चला की 'मानव श्रम के समुचित प्रयोग से' उस क्षेत्र की तो काया ही पलट गई है.\n",
      "Average BLEU score : 0.4866960565294154 \n",
      "\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "Transliterating sentence  31\n",
      "Original Code mized text : iska vishisht vidyutiya pratirodh 4.9 hai jo platinum ka lagbhag adha hai.\n",
      "\n",
      "Original Native Hindi convertion : इसका विशिष्ट विद्युतीय प्रतिरोध ४.९ है जो प्लैटिनम का लगभग आधा है।\n",
      "\n",
      "Transliterated to Hindi : इसका विशिष्ट विद्युतीय प्रतिरोध ४.९ है जो प्लैटिनम का लगभग आधा है.\n",
      "Average BLEU score : 0.5123741140294238 \n",
      "\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "Transliterating sentence  41\n",
      "Original Code mized text : ek baar to unhone Jawaharlal Nehru ko patr likhkar krantikari navyuakon ka saath dene par buri tarah fatkaar bhi lagaai thee.\n",
      "\n",
      "Original Native Hindi convertion : एक बार तो उन्होंने जवाहरलाल नेहरू को पत्र लिखकर क्रान्तिकारी नवयुवकों का साथ देने पर बुरी तरह फटकार भी लगायी थी।\n",
      "\n",
      "Transliterated to Hindi : एक बार तो उन्होंने जवाहरलाल नेहरू को पात्र लिखकर क्रन्तिकारी नवयुवकों का साथ देने पर बुरी तरह फटकार भी लगाईं थी.\n",
      "Average BLEU score : 0.5062429406134188 \n",
      "\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "Transliterating sentence  51\n",
      "Original Code mized text : ek vidhi inke Iksponenshiyal falan ke falan ke roop men paribhashit karti hai-\n",
      "\n",
      "Original Native Hindi convertion : एक विधि इनको इक्सपोनेन्शियल फलन के फलन के रूप में परिभाषित करती है-\n",
      "\n",
      "Transliterated to Hindi : एक विधि इनके इक्स्पोनेंशियल फलां के फलां के रूप में परिभाषित करती है-\n",
      "Average BLEU score : 0.4656101215487338 \n",
      "\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "Transliterating sentence  61\n",
      "Original Code mized text : Sanvidhan ke Lesotho men aya bal ke prakashan ke baad prarambh adesh hai .\n",
      "\n",
      "Original Native Hindi convertion : संविधान के लेसोथो में आया बल के प्रकाशन के बाद प्रारंभ आदेश है ।\n",
      "\n",
      "Transliterated to Hindi : संविधान के लेसोथो में आया बल के प्रकाशन के बाद प्रारम्भ आदेश है .\n",
      "Average BLEU score : 0.4972013208182766 \n",
      "\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "Transliterating sentence  71\n",
      "Original Code mized text : kai suvidhayen aur adhikansh credit card bhi grahakon ko anumati dete hain ki ve baink ki jaankaari pradan karke bhugtaan kar sakte hain aur aadata ko grahak ke khaate se (pratyaksh naame) bhugtaan ka aahran karne dete hain.\n",
      "\n",
      "Original Native Hindi convertion : कई सुविधाएं और अधिकांश क्रेडिट कार्ड भी ग्राहकों को अनुमति देते हैं कि वे बैंक की जानकारी प्रदान करके भुगतान कर सकते हैं और आदाता को ग्राहक के खाते से (प्रत्यक्ष नामे) भुगतान का आहरण करने देते हैं।\n",
      "\n",
      "Transliterated to Hindi : कई सुविधाएँ और अधिकांश क्रेडिट कार्ड भी ग्राहकों को अनुमति देते हैं की वे बैंक की जानकारी प्रदान करके भुगतान कर सकते हैं और आदत को ग्राहक के खाते से (प्रत्यक्ष नाम) भुगतान का आहरण करने देते हैं.\n",
      "Average BLEU score : 0.49510576359539016 \n",
      "\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "Transliterating sentence  81\n",
      "Original Code mized text : ramayana aur mahabharata ki gathaon dwara yeh adarsh jan jan tak pahunchte hain.\n",
      "\n",
      "Original Native Hindi convertion : रामायण और महाभारत की गाथाओं द्वारा यह आदर्श जन जन तक पहुँचते हैं।\n",
      "\n",
      "Transliterated to Hindi : रामायण और महाभारत की गाथाओं द्वारा यह आदर्श जान जान तक पहुँचते हैं.\n",
      "Average BLEU score : 0.47283733420415003 \n",
      "\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "Transliterating sentence  91\n",
      "Original Code mized text : ismen Safed, sugandhit Pushp lagte hain.\n",
      "\n",
      "Original Native Hindi convertion : इसमें सफेद, सुगंधित पुष्प लगते हैं।\n",
      "\n",
      "Transliterated to Hindi : इसमें सफ़ेद, सुगन्धित पुष्प लगते हैं.\n",
      "Average BLEU score : 0.4747054924984114 \n",
      "\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "Average Bleu Score for Train Set :  0.48512822887183105\n"
     ]
    }
   ],
   "source": [
    "# Testing out Google Transliterate package\n",
    "from google.transliteration import transliterate_word\n",
    "def transliterate_all_alphanumeric_parts(sentence, lang_code='hi'):\n",
    "    transliterated_sentence = []\n",
    "    words = sentence.split()\n",
    "\n",
    "    for word in words:\n",
    "        # Use regex to find all alphanumeric parts in the word\n",
    "        parts = re.findall(r'[a-zA-Z0-9]+|[^a-zA-Z0-9]+', word)\n",
    "        \n",
    "        transliterated_word = \"\"\n",
    "        \n",
    "        for part in parts:\n",
    "            if part.isalnum():  # Transliterate only alphanumeric parts\n",
    "                try:\n",
    "                    # Transliterate the alphanumeric part\n",
    "                    suggestions = transliterate_word(part, lang_code=lang_code)\n",
    "                    transliterated_part = suggestions[0] if suggestions else part\n",
    "                except IndexError:\n",
    "                    # If transliteration fails, keep the alphanumeric part as is\n",
    "                    transliterated_part = part\n",
    "            else:\n",
    "                # Keep non-alphanumeric parts (like \"-\" or spaces) as is\n",
    "                transliterated_part = part\n",
    "            \n",
    "            transliterated_word += transliterated_part\n",
    "        \n",
    "        transliterated_sentence.append(transliterated_word)\n",
    "\n",
    "    return ' '.join(transliterated_sentence)\n",
    "\n",
    "google_bleu_scores = []\n",
    "lang = 'hi'\n",
    "for i in range(hinglish_sentences.size):\n",
    "\n",
    "    print(i)\n",
    "    # transformed_sentence = transliterate_text(hinglish_sentences[i],lang_code = lang)\n",
    "    transformed_sentence = transliterate_all_alphanumeric_parts(hinglish_sentences[i], lang_code=lang)\n",
    "    reference = [hindi_true[i].split()]\n",
    "    # print(transformed_sentence)\n",
    "    transformed_tokens = transformed_sentence.split()\n",
    "    bleu_score = sentence_bleu(reference, transformed_tokens)\n",
    "    google_bleu_scores.append(bleu_score)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(\"Transliterating sentence \", i+1)\n",
    "        print('Original Code mized text :', hinglish_sentences[i])\n",
    "        print('Original Native Hindi convertion :', hindi_true[i])\n",
    "        print('Transliterated to Hindi :', transformed_sentence)\n",
    "        print('Average BLEU score :', np.mean(google_bleu_scores), '\\n')\n",
    "\n",
    "average_bleu_score = np.mean(google_bleu_scores)\n",
    "print('Average Bleu Score for Train Set : ', average_bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e42dbb9-f107-4a44-ab52-6634263b18d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Transliterate model is very accurate but takes time to transliterate the sentence\n"
     ]
    }
   ],
   "source": [
    "print('Google Transliterate model is very accurate but takes time to transliterate the sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f509461-2b7f-4350-95a4-06d1da2a03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai4bharat.transliteration import XlitEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f18e0901-fa52-45d8-9d52-70dec88951aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithish\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\ai4bharat\\transliteration\\xlit_src.py:499: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load( weight_path, map_location=torch.device(self.device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hi': ['कम्प्यूटर', 'कंप्यूटर', 'कम्पूटर', 'कम्पुटर', 'कम्प्युटर']}\n"
     ]
    }
   ],
   "source": [
    "e = XlitEngine(\"hi\")\n",
    "out = e.translit_word(\"computer\", topk=5, beam_width=10)\n",
    "print(out)\n",
    "# output:{'hi': ['कम्प्यूटर', 'कंप्यूटर', 'कम्पूटर', 'कम्पुटर', 'कम्प्युटर']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9766ba30-d9bf-4400-8c9d-d5b8e8061893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hi...\n",
      "यहाँ पर भगवन बहुबली कि 18 मीटर\n",
      "Transliterating sentence  1\n",
      "Original Code mized text : yahan par bhagwan Bahubali ki 18 meter\n",
      "\n",
      "Original Native Hindi convertion : यहाँ पर भगवान बाहुबली की १८ मी.\n",
      "\n",
      "Transliterated to Hindi : यहाँ पर भगवन बहुबली कि 18 मीटर\n",
      "Average BLEU score : 6.968148412761692e-155 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithish\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Nithish\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "समझा-परखा\n",
      "Transliterating sentence  2\n",
      "Original Code mized text : samjha-parkha\n",
      "\n",
      "Original Native Hindi convertion : समझा-परखा\n",
      "\n",
      "Transliterated to Hindi : समझा-परखा\n",
      "Average BLEU score : 3.484074206380846e-155 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithish\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "जब कमिश्नर अरुण के साठ बात कर रहे थे, तो सपना आती है आउर् आयुक्त अरुण से छुपने को कहता है.\n",
      "Transliterating sentence  3\n",
      "Original Code mized text : jab kamishnar Arun ke saath baat kar rahe the, to Sapna aati hai aur aayukt Arun se chhupne ko kahta hai.\n",
      "\n",
      "Original Native Hindi convertion : जब कमिश्नर अरुण के साथ बात कर रहे थे, तो सपना आती है और आयुक्त अरुण से छुपने को कहता है।\n",
      "\n",
      "Transliterated to Hindi : जब कमिश्नर अरुण के साठ बात कर रहे थे, तो सपना आती है आउर् आयुक्त अरुण से छुपने को कहता है.\n",
      "Average BLEU score : 0.22374677077485583 \n",
      "\n",
      "जोशी ने एसी में पुरातत्वविदों के सामर्थन का उठान किया आउर् मौलिक को बहार करने का प्रयास किया, लेकिन सरकार ने जोशी कि बजाय उसे खारिज कर दिया.\n",
      "Transliterating sentence  4\n",
      "Original Code mized text : Joshi ne ASI men purattwavidon ke samarthan ka uthan kiya aur maulik ko bahar karne ka prayas kiya, lekin sarkar ne Joshi ki bajay use kharij kar diya.\n",
      "\n",
      "Original Native Hindi convertion : जोशी ने एएसआई में पुरातत्वविदों के समर्थन का उत्थान किया और मौलिक को बाहर करने का प्रयास किया, लेकिन सरकार ने जोशी की बजाय उसे खारिज कर दिया।\n",
      "\n",
      "Transliterated to Hindi : जोशी ने एसी में पुरातत्वविदों के सामर्थन का उठान किया आउर् मौलिक को बहार करने का प्रयास किया, लेकिन सरकार ने जोशी कि बजाय उसे खारिज कर दिया.\n",
      "Average BLEU score : 0.27380046881733766 \n",
      "\n",
      "अगेती परीक्षित शर्म संस्कृत भाषा के प्रतिष्ठित साहित्यकार हैं.\n",
      "Transliterating sentence  5\n",
      "Original Code mized text : Ageti Parikshit Sharma Sanskrut Bhasha ke pratishthit sahityakar hain.\n",
      "\n",
      "Original Native Hindi convertion : आगेटि परीक्षित शर्मा संस्कृत भाषा के प्रतिष्ठित साहित्यकार हैं।\n",
      "\n",
      "Transliterated to Hindi : अगेती परीक्षित शर्म संस्कृत भाषा के प्रतिष्ठित साहित्यकार हैं.\n",
      "Average BLEU score : 0.31246797059951015 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m e \u001b[38;5;241m=\u001b[39m XlitEngine(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hinglish_sentences\u001b[38;5;241m.\u001b[39msize):\n\u001b[1;32m----> 7\u001b[0m     transformed_sentence \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mtranslit_sentence(hinglish_sentences[i])[lang]\n\u001b[0;32m      8\u001b[0m     reference \u001b[38;5;241m=\u001b[39m [hindi_true[i]\u001b[38;5;241m.\u001b[39msplit()]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(transformed_sentence)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\ai4bharat\\transliteration\\xlit_src.py:764\u001b[0m, in \u001b[0;36mXlitEngine.translit_sentence\u001b[1;34m(self, eng_sentence, lang_code, beam_width)\u001b[0m\n\u001b[0;32m    762\u001b[0m out_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m eng_sentence\u001b[38;5;241m.\u001b[39msplit():\n\u001b[1;32m--> 764\u001b[0m     res_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang_model[la]\u001b[38;5;241m.\u001b[39minferencer(word, beam_width \u001b[38;5;241m=\u001b[39m beam_width)\n\u001b[0;32m    765\u001b[0m     out_str \u001b[38;5;241m=\u001b[39m out_str \u001b[38;5;241m+\u001b[39m res_[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    766\u001b[0m res_dict[la] \u001b[38;5;241m=\u001b[39m out_str[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\ai4bharat\\transliteration\\xlit_src.py:576\u001b[0m, in \u001b[0;36mXlitPiston.inferencer\u001b[1;34m(self, sequence, beam_width)\u001b[0m\n\u001b[0;32m    573\u001b[0m     p\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m seg[p][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inchar_set:\n\u001b[1;32m--> 576\u001b[0m     lit_seg\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharacter_model(seg[p], beam_width\u001b[38;5;241m=\u001b[39mbeam_width))\n\u001b[0;32m    577\u001b[0m     p\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m seg[p][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numsym_set: \u001b[38;5;66;03m# num & punc\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\ai4bharat\\transliteration\\xlit_src.py:507\u001b[0m, in \u001b[0;36mXlitPiston.character_model\u001b[1;34m(self, word, beam_width)\u001b[0m\n\u001b[0;32m    505\u001b[0m in_vec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_glyph_obj\u001b[38;5;241m.\u001b[39mword2xlitvec(word))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m## change to active or passive beam\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m p_out_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mactive_beam_inference(in_vec, beam_width \u001b[38;5;241m=\u001b[39m beam_width)\n\u001b[0;32m    508\u001b[0m p_result \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgt_glyph_obj\u001b[38;5;241m.\u001b[39mxlitvec2word(out\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()) \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m p_out_list]\n\u001b[0;32m    510\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoc_sanity\u001b[38;5;241m.\u001b[39mreposition(p_result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\ai4bharat\\transliteration\\xlit_src.py:319\u001b[0m, in \u001b[0;36mSeq2Seq.active_beam_inference\u001b[1;34m(self, src, beam_width, max_tgt_sz)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# dec_hidden: dec_layers, 1, hidden_dim\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# dec_output: 1, output_dim\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m dec_output, dec_hidden, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder( x \u001b[38;5;241m=\u001b[39m p_tup[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), \u001b[38;5;66;03m#dec_input: (1,1)\u001b[39;00m\n\u001b[0;32m    320\u001b[0m                                     hidden \u001b[38;5;241m=\u001b[39m p_tup[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    321\u001b[0m                                     enc_output \u001b[38;5;241m=\u001b[39m enc_output, )\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m## π{prob} = Σ{log(prob)} -> to prevent diminishing\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# dec_output: (1, output_dim)\u001b[39;00m\n\u001b[0;32m    325\u001b[0m dec_output \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlog_softmax(dec_output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\ai4bharat\\transliteration\\xlit_src.py:212\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, hidden, enc_output)\u001b[0m\n\u001b[0;32m    207\u001b[0m     x, aw \u001b[38;5;241m=\u001b[39m x, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# passing the concatenated vector to the GRU\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# output: (batch_size, n_layers, hidden_size)\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# hidden: n_layers, batch_size, hidden_size | if LSTM (h_n, c_n)\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec_rnn(x, hidden) \u001b[38;5;28;01mif\u001b[39;00m hidden \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec_rnn(x)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# output :shp: (batch_size * 1, hidden_size)\u001b[39;00m\n\u001b[0;32m    215\u001b[0m output \u001b[38;5;241m=\u001b[39m  output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mt_final_project\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1124\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1125\u001b[0m         hx,\n\u001b[0;32m   1126\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights,\n\u001b[0;32m   1127\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m   1128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[0;32m   1130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[0;32m   1131\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[0;32m   1133\u001b[0m     )\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1137\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Testing using AI4Bharath transliterator\n",
    "ai4b_bleu_scores = []\n",
    "lang = 'hi'\n",
    "e = XlitEngine('hi')\n",
    "for i in range(hinglish_sentences.size):\n",
    "\n",
    "    transformed_sentence = e.translit_sentence(hinglish_sentences[i])[lang]\n",
    "    reference = [hindi_true[i].split()]\n",
    "    print(transformed_sentence)\n",
    "    transformed_tokens = transformed_sentence.split()\n",
    "    bleu_score = sentence_bleu(reference, transformed_tokens)\n",
    "    ai4b_bleu_scores.append(bleu_score)\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        print(\"Transliterating sentence \", i+1)\n",
    "        print('Original Code mized text :', hinglish_sentences[i])\n",
    "        print('Original Native Hindi convertion :', hindi_true[i])\n",
    "        print('Transliterated to Hindi :', transformed_sentence)\n",
    "        print('Average BLEU score :', np.mean(ai4b_bleu_scores), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a08de3-4cd9-41b7-8b4c-a37a26c58f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_bleu_score = np.mean(ai4b_bleu_scores)\n",
    "print('Average Bleu Score for Train Set : ', average_bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c0520-4097-4b10-ab44-d9b8e9567615",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hinglish_sentences[12])\n",
    "print(hindi_true[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef9f4ce-9db2-4666-aa0d-3ae3840e1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "suggestions = transliterate_word('America', lang_code='ja')\n",
    "print(suggestions[0])\n",
    "\n",
    "#suggestions = transliterate_word('#20', lang_code='hi')\n",
    "#print(suggestions[0])\n",
    "\n",
    "def transliterate_sentence(sentence, lang_code='hi'):\n",
    "    transliterated_sentence = []\n",
    "    words = sentence.split()\n",
    "    \n",
    "    for word in words:\n",
    "        # Check if word is alphanumeric\n",
    "        if word.isalnum():\n",
    "            try:\n",
    "                # Get the first suggestion for the transliterated word\n",
    "                suggestions = transliterate_word(word, lang_code=lang_code)\n",
    "                transliterated_word = suggestions[0] if suggestions else word\n",
    "                transliterated_sentence.append(transliterated_word)\n",
    "            except IndexError:\n",
    "                # Handle cases where no suggestions are returned\n",
    "                transliterated_sentence.append(word)\n",
    "        else:\n",
    "            # Skip non-alphanumeric words\n",
    "            transliterated_sentence.append(word)\n",
    "\n",
    "    return ' '.join(transliterated_sentence)\n",
    "\n",
    "sentence = hinglish_sentences[12]\n",
    "print(transliterate_sentence(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac87c7-0622-4fbb-9c23-acbd9bb6e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliterate_all_alphanumeric_parts(sentence, lang_code='hi'):\n",
    "    transliterated_sentence = []\n",
    "    words = sentence.split()\n",
    "\n",
    "    for word in words:\n",
    "        # Use regex to find all alphanumeric parts in the word\n",
    "        parts = re.findall(r'[a-zA-Z0-9]+|[^a-zA-Z0-9]+', word)\n",
    "        \n",
    "        transliterated_word = \"\"\n",
    "        \n",
    "        for part in parts:\n",
    "            if part.isalnum():  # Transliterate only alphanumeric parts\n",
    "                try:\n",
    "                    # Transliterate the alphanumeric part\n",
    "                    suggestions = transliterate_word(part, lang_code=lang_code)\n",
    "                    transliterated_part = suggestions[0] if suggestions else part\n",
    "                except IndexError:\n",
    "                    # If transliteration fails, keep the alphanumeric part as is\n",
    "                    transliterated_part = part\n",
    "            else:\n",
    "                # Keep non-alphanumeric parts (like \"-\" or spaces) as is\n",
    "                transliterated_part = part\n",
    "            \n",
    "            transliterated_word += transliterated_part\n",
    "        \n",
    "        transliterated_sentence.append(transliterated_word)\n",
    "\n",
    "    return ' '.join(transliterated_sentence)\n",
    "\n",
    "# Example usage\n",
    "sentence = \"This is an example with uprichar-Wasu and another-word.\"\n",
    "print(transliterate_all_alphanumeric_parts(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dffc3f8-cec6-49b1-b945-19eebf16b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transliterate_all_alphanumeric_parts(hinglish_sentences[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c07555-5f10-4393-986f-6df801c3570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transliterate_all_alphanumeric_parts(hinglish_sentences[24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b821d8d5-ac81-4ae8-932c-20792b6f088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hindi_true[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b785e-58f8-4baa-a100-0bac5beeff2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
